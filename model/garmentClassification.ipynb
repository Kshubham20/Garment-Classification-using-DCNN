{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyObBW4OVMKts17XVC3+cVLS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S14wc1tetBgx","executionInfo":{"status":"ok","timestamp":1657976484463,"user_tz":-330,"elapsed":34835,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"07c24a6d-d2b4-4e07-b000-aa387d41bce4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os, shutil\n","import numpy as np\n","\n","from matplotlib import image, pyplot\n","from skimage.transform import resize\n","\n","\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n","\n","from keras import callbacks\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, f1_score, recall_score,classification_report,roc_curve, auc \n","from sklearn.svm import SVC\n","from sklearn import svm"],"metadata":{"id":"QNpgbd5NtgJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_PATH = '/content/drive/MyDrive/MlProject1/ML_project1/'\n","westEth=[]\n","labelwe=[]\n","hashList=[]\n","count=2\n","for folder in os.listdir(DATA_PATH):\n","    if folder==\"Gender\":\n","      continue;\n","    print(\">>>Reading \",folder)\n","    count-=1\n","    print(count)\n","    \n","    for file in os.listdir(DATA_PATH+folder):\n","         if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n","            img = image.imread(DATA_PATH+folder+'/'+file)\n","            hsh = hash(tuple(np.array(img).flatten()))\n","            if(hsh not in hashList):\n","              westEth.append(resize(img, (156, 156, 3)))\n","              hashList.append(hsh)\n","              labelwe.append(count)\n","westEth=np.array(westEth)\n","labelwe=np.array(labelwe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y63ZZBUOthpe","executionInfo":{"status":"ok","timestamp":1657977983347,"user_tz":-330,"elapsed":264897,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"cb5d4ef8-5f6e-41d5-bd43-87f726a4b99f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":[">>>Reading  western\n","1\n",">>>Reading  ethenic\n","0\n"]}]},{"cell_type":"code","source":["resultPath = '/content/drive/MyDrive/Results1'\n","train_folder = os.listdir(DATA_PATH).remove(\"Gender\")"],"metadata":{"id":"hCm5cOnxtqPm","executionInfo":{"status":"ok","timestamp":1657978191096,"user_tz":-330,"elapsed":442,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(\"Number of Ethenic\",len(labelwe[labelwe==0]))\n","print(\"Number of western\",len(labelwe[labelwe==1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IYpDK4n8ZkS","executionInfo":{"status":"ok","timestamp":1657978193072,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"9f80b803-255b-450d-f182-61ccfca921b4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Ethenic 1715\n","Number of western 1873\n"]}]},{"cell_type":"code","source":["print(\"western/ethenic data shape : \",westEth.shape,\" Label shape : \",labelwe.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZklbNce-8duu","executionInfo":{"status":"ok","timestamp":1657978195819,"user_tz":-330,"elapsed":762,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"c77f829e-1e5f-4383-a038-0690c764d5d6"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["western/ethenic data shape :  (3588, 156, 156, 3)  Label shape :  (3588,)\n"]}]},{"cell_type":"code","source":["testPercentage=0.3\n","x_train,x_test,y_train,y_test = train_test_split(westEth,labelwe,test_size = testPercentage,random_state=50, stratify=labelwe,shuffle=True)"],"metadata":{"id":"mWSktZNG8gtm","executionInfo":{"status":"ok","timestamp":1657978202347,"user_tz":-330,"elapsed":4559,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n","print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzD0iuMO8ldm","executionInfo":{"status":"ok","timestamp":1657978204860,"user_tz":-330,"elapsed":659,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"f53d364a-61ba-4d6c-df20-2afbb400222f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape :  (2511, 156, 156, 3)  y_train shape :  (2511,)\n","x_test shape :  (1077, 156, 156, 3)  y_test shape :  (1077,)\n"]}]},{"cell_type":"code","source":["print(\"Number of train ethenic\",len(y_train[y_train==0]))\n","print(\"Number of train western\",len(y_train[y_train==1]))\n","\n","print(\"Number of test  ethenic\",len(y_test[y_test==0]))\n","print(\"Number of test western\",len(y_test[y_test==1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8A-QeYK8pYL","executionInfo":{"status":"ok","timestamp":1657978209640,"user_tz":-330,"elapsed":436,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"be89fc67-2aad-4b39-ba6b-717fd027304f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train ethenic 1200\n","Number of train western 1311\n","Number of test  ethenic 515\n","Number of test western 562\n"]}]},{"cell_type":"code","source":["NO_OF_EPOCHS=100\n","BATCH_SIZE=32\n","\n","model2=Sequential()\n","model2.add(Conv2D(32,kernel_size=3, padding='same',activation='relu',input_shape=(156, 156,3)))\n","model2.add(MaxPool2D(pool_size=(2, 2)))\n","model2.add(Conv2D(64,kernel_size=3, padding='same',activation='relu'))\n","model2.add(MaxPool2D(pool_size=(2, 2)))\n","model2.add(Conv2D(128,kernel_size=3, padding='same',activation='relu'))\n","model2.add(Dropout(0.1))\n","model2.add(Flatten())\n","model2.add(Dense(128,activation='relu'))\n","model2.add(Dropout(0.1))\n","model2.add(Dense(1,activation='sigmoid'))\n","model2.summary()\n","model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bA9LpxNU8s4f","executionInfo":{"status":"ok","timestamp":1657978213053,"user_tz":-330,"elapsed":1244,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"b30b0caf-d39d-4e7e-f0fd-0a739ba77713"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 156, 156, 32)      896       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 78, 78, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 78, 78, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 39, 39, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 39, 39, 128)       73856     \n","                                                                 \n"," dropout (Dropout)           (None, 39, 39, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 194688)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               24920192  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 25,013,569\n","Trainable params: 25,013,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n","csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n","reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=2, min_lr=0.001)\n","model2.fit(x_train,y_train,epochs=NO_OF_EPOCHS,verbose=1,batch_size=BATCH_SIZE,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaSTqRhF81Nh","executionInfo":{"status":"ok","timestamp":1657900508107,"user_tz":-330,"elapsed":5848692,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"d43457a1-2ceb-48a9-9ce2-f6010b4052da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","79/79 [==============================] - ETA: 0s - loss: 0.7880 - accuracy: 0.5129\n","Epoch 1: val_accuracy improved from -inf to 0.58032, saving model to /content/drive/MyDrive/Results1/checkpoint-0001.hdf5\n","79/79 [==============================] - 105s 1s/step - loss: 0.7880 - accuracy: 0.5129 - val_loss: 0.6792 - val_accuracy: 0.5803 - lr: 0.0010\n","Epoch 2/100\n","79/79 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.6149\n","Epoch 2: val_accuracy improved from 0.58032 to 0.64624, saving model to /content/drive/MyDrive/Results1/checkpoint-0002.hdf5\n","79/79 [==============================] - 105s 1s/step - loss: 0.6579 - accuracy: 0.6149 - val_loss: 0.6477 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 3/100\n","79/79 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.6766\n","Epoch 3: val_accuracy did not improve from 0.64624\n","79/79 [==============================] - 106s 1s/step - loss: 0.5992 - accuracy: 0.6766 - val_loss: 0.6599 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 4/100\n","79/79 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.7415\n","Epoch 4: val_accuracy improved from 0.64624 to 0.66574, saving model to /content/drive/MyDrive/Results1/checkpoint-0004.hdf5\n","79/79 [==============================] - 105s 1s/step - loss: 0.5254 - accuracy: 0.7415 - val_loss: 0.6527 - val_accuracy: 0.6657 - lr: 0.0010\n","Epoch 5/100\n","79/79 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.7997\n","Epoch 5: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 104s 1s/step - loss: 0.4158 - accuracy: 0.7997 - val_loss: 0.7572 - val_accuracy: 0.6286 - lr: 0.0010\n","Epoch 6/100\n","79/79 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.8662\n","Epoch 6: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 104s 1s/step - loss: 0.2878 - accuracy: 0.8662 - val_loss: 0.9109 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 7/100\n","79/79 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9235\n","Epoch 7: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 103s 1s/step - loss: 0.1767 - accuracy: 0.9235 - val_loss: 1.2401 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 8/100\n","79/79 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9634\n","Epoch 8: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 103s 1s/step - loss: 0.1125 - accuracy: 0.9634 - val_loss: 1.3589 - val_accuracy: 0.6648 - lr: 0.0010\n","Epoch 9/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9805\n","Epoch 9: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 107s 1s/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 1.9971 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 10/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9753\n","Epoch 10: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 105s 1s/step - loss: 0.0568 - accuracy: 0.9753 - val_loss: 2.1814 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 11/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9817\n","Epoch 11: val_accuracy did not improve from 0.66574\n","79/79 [==============================] - 105s 1s/step - loss: 0.0499 - accuracy: 0.9817 - val_loss: 1.8299 - val_accuracy: 0.6630 - lr: 0.0010\n","Epoch 12/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9892\n","Epoch 12: val_accuracy improved from 0.66574 to 0.66945, saving model to /content/drive/MyDrive/Results1/checkpoint-0012.hdf5\n","79/79 [==============================] - 106s 1s/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 2.1620 - val_accuracy: 0.6695 - lr: 0.0010\n","Epoch 13/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9928\n","Epoch 13: val_accuracy did not improve from 0.66945\n","79/79 [==============================] - 105s 1s/step - loss: 0.0326 - accuracy: 0.9928 - val_loss: 1.9931 - val_accuracy: 0.6695 - lr: 0.0010\n","Epoch 14/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9956\n","Epoch 14: val_accuracy did not improve from 0.66945\n","79/79 [==============================] - 103s 1s/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 2.1866 - val_accuracy: 0.6667 - lr: 0.0010\n","Epoch 15/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9976\n","Epoch 15: val_accuracy improved from 0.66945 to 0.67967, saving model to /content/drive/MyDrive/Results1/checkpoint-0015.hdf5\n","79/79 [==============================] - 107s 1s/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 2.2830 - val_accuracy: 0.6797 - lr: 0.0010\n","Epoch 16/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9988\n","Epoch 16: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 2.4547 - val_accuracy: 0.6760 - lr: 0.0010\n","Epoch 17/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9944\n","Epoch 17: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 3.1215 - val_accuracy: 0.6518 - lr: 0.0010\n","Epoch 18/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9948\n","Epoch 18: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 2.8705 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 19/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9920\n","Epoch 19: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 2.4989 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 20/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9960\n","Epoch 20: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 106s 1s/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 2.7143 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 21/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9988\n","Epoch 21: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 108s 1s/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 2.7931 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 22/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9940\n","Epoch 22: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 106s 1s/step - loss: 0.0268 - accuracy: 0.9940 - val_loss: 2.3186 - val_accuracy: 0.6713 - lr: 0.0010\n","Epoch 23/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9976\n","Epoch 23: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 2.9392 - val_accuracy: 0.6722 - lr: 0.0010\n","Epoch 24/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n","Epoch 24: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 2.7514 - val_accuracy: 0.6732 - lr: 0.0010\n","Epoch 25/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n","Epoch 25: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 3.0428 - val_accuracy: 0.6741 - lr: 0.0010\n","Epoch 26/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9972\n","Epoch 26: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 106s 1s/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 3.0757 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 27/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9976\n","Epoch 27: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 3.0036 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 28/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9956\n","Epoch 28: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 2.8335 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 29/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n","Epoch 29: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 3.2214 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 30/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9976\n","Epoch 30: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 3.4220 - val_accuracy: 0.6444 - lr: 0.0010\n","Epoch 31/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 31: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.6218 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 32/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 32: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.6207 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 33/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n","Epoch 33: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 3.5752 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 34/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9988\n","Epoch 34: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 3.3585 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 35/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9984\n","Epoch 35: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 3.2180 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 36/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9976\n","Epoch 36: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 3.3800 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 37/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9992\n","Epoch 37: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 3.3483 - val_accuracy: 0.6388 - lr: 0.0010\n","Epoch 38/100\n","79/79 [==============================] - ETA: 0s - loss: 9.5878e-04 - accuracy: 0.9996\n","Epoch 38: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 105s 1s/step - loss: 9.5878e-04 - accuracy: 0.9996 - val_loss: 3.5222 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 39/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 39: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 3.5805 - val_accuracy: 0.6388 - lr: 0.0010\n","Epoch 40/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9992\n","Epoch 40: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 3.3019 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 41/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9992\n","Epoch 41: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 3.3873 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 42/100\n","79/79 [==============================] - ETA: 0s - loss: 4.4052e-04 - accuracy: 1.0000\n","Epoch 42: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 4.4052e-04 - accuracy: 1.0000 - val_loss: 3.4884 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 43/100\n","79/79 [==============================] - ETA: 0s - loss: 3.4612e-04 - accuracy: 1.0000\n","Epoch 43: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 3.4612e-04 - accuracy: 1.0000 - val_loss: 3.5045 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 44/100\n","79/79 [==============================] - ETA: 0s - loss: 7.7717e-04 - accuracy: 0.9996\n","Epoch 44: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 7.7717e-04 - accuracy: 0.9996 - val_loss: 3.5057 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 45/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9976\n","Epoch 45: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 107s 1s/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 3.3377 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 46/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9948\n","Epoch 46: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0110 - accuracy: 0.9948 - val_loss: 3.6596 - val_accuracy: 0.6388 - lr: 0.0010\n","Epoch 47/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9888\n","Epoch 47: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0589 - accuracy: 0.9888 - val_loss: 2.7417 - val_accuracy: 0.6360 - lr: 0.0010\n","Epoch 48/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9980\n","Epoch 48: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 3.1247 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 49/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9992\n","Epoch 49: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 3.1933 - val_accuracy: 0.6630 - lr: 0.0010\n","Epoch 50/100\n","79/79 [==============================] - ETA: 0s - loss: 5.5116e-04 - accuracy: 1.0000\n","Epoch 50: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 5.5116e-04 - accuracy: 1.0000 - val_loss: 3.5323 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 51/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 51: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.9306 - val_accuracy: 0.6453 - lr: 0.0010\n","Epoch 52/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9873\n","Epoch 52: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 3.0458 - val_accuracy: 0.6574 - lr: 0.0010\n","Epoch 53/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9972\n","Epoch 53: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 3.3358 - val_accuracy: 0.6574 - lr: 0.0010\n","Epoch 54/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9988\n","Epoch 54: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 3.3549 - val_accuracy: 0.6648 - lr: 0.0010\n","Epoch 55/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968\n","Epoch 55: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 3.3835 - val_accuracy: 0.6704 - lr: 0.0010\n","Epoch 56/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9980\n","Epoch 56: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 3.2024 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 57/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 57: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 3.4333 - val_accuracy: 0.6592 - lr: 0.0010\n","Epoch 58/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9980\n","Epoch 58: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: 3.9487 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 59/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9980\n","Epoch 59: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 3.3723 - val_accuracy: 0.6592 - lr: 0.0010\n","Epoch 60/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n","Epoch 60: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 4.0789 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 61/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n","Epoch 61: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 3.7211 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 62/100\n","79/79 [==============================] - ETA: 0s - loss: 4.4967e-04 - accuracy: 1.0000\n","Epoch 62: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 4.4967e-04 - accuracy: 1.0000 - val_loss: 3.7951 - val_accuracy: 0.6630 - lr: 0.0010\n","Epoch 63/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996\n","Epoch 63: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 3.5146 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 64/100\n","79/79 [==============================] - ETA: 0s - loss: 4.2999e-04 - accuracy: 1.0000\n","Epoch 64: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 4.2999e-04 - accuracy: 1.0000 - val_loss: 3.6090 - val_accuracy: 0.6592 - lr: 0.0010\n","Epoch 65/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9984\n","Epoch 65: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 3.4618 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 66/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964\n","Epoch 66: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 3.7936 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 67/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n","Epoch 67: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 3.6827 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 68/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n","Epoch 68: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 3.6094 - val_accuracy: 0.6397 - lr: 0.0010\n","Epoch 69/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9972\n","Epoch 69: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 104s 1s/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 3.4975 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 70/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984\n","Epoch 70: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 3.6812 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 71/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n","Epoch 71: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 4.3601 - val_accuracy: 0.6444 - lr: 0.0010\n","Epoch 72/100\n","79/79 [==============================] - ETA: 0s - loss: 8.8766e-04 - accuracy: 0.9996\n","Epoch 72: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 8.8766e-04 - accuracy: 0.9996 - val_loss: 4.2235 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 73/100\n","79/79 [==============================] - ETA: 0s - loss: 5.6023e-04 - accuracy: 1.0000\n","Epoch 73: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 5.6023e-04 - accuracy: 1.0000 - val_loss: 4.4143 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 74/100\n","79/79 [==============================] - ETA: 0s - loss: 4.7186e-04 - accuracy: 1.0000\n","Epoch 74: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 4.7186e-04 - accuracy: 1.0000 - val_loss: 4.7784 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 75/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 75: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 4.2307 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 76/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9984\n","Epoch 76: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0100 - accuracy: 0.9984 - val_loss: 4.2167 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 77/100\n","79/79 [==============================] - ETA: 0s - loss: 8.4339e-04 - accuracy: 1.0000\n","Epoch 77: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 8.4339e-04 - accuracy: 1.0000 - val_loss: 4.1477 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 78/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9976\n","Epoch 78: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 4.5155 - val_accuracy: 0.6416 - lr: 0.0010\n","Epoch 79/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9956\n","Epoch 79: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 4.3556 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 80/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996\n","Epoch 80: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 4.5536 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 81/100\n","79/79 [==============================] - ETA: 0s - loss: 3.2864e-04 - accuracy: 1.0000\n","Epoch 81: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 3.2864e-04 - accuracy: 1.0000 - val_loss: 4.6099 - val_accuracy: 0.6518 - lr: 0.0010\n","Epoch 82/100\n","79/79 [==============================] - ETA: 0s - loss: 2.9413e-04 - accuracy: 1.0000\n","Epoch 82: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 2.9413e-04 - accuracy: 1.0000 - val_loss: 4.6682 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 83/100\n","79/79 [==============================] - ETA: 0s - loss: 2.5085e-04 - accuracy: 1.0000\n","Epoch 83: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 2.5085e-04 - accuracy: 1.0000 - val_loss: 4.7224 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 84/100\n","79/79 [==============================] - ETA: 0s - loss: 5.8596e-05 - accuracy: 1.0000\n","Epoch 84: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 5.8596e-05 - accuracy: 1.0000 - val_loss: 4.7563 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 85/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9988\n","Epoch 85: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 101s 1s/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 5.1472 - val_accuracy: 0.6453 - lr: 0.0010\n","Epoch 86/100\n","79/79 [==============================] - ETA: 0s - loss: 5.6514e-04 - accuracy: 1.0000\n","Epoch 86: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 5.6514e-04 - accuracy: 1.0000 - val_loss: 5.0922 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 87/100\n","79/79 [==============================] - ETA: 0s - loss: 2.3867e-04 - accuracy: 1.0000\n","Epoch 87: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 2.3867e-04 - accuracy: 1.0000 - val_loss: 5.0798 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 88/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 88: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 101s 1s/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 4.6569 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 89/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9980\n","Epoch 89: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 4.9546 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 90/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n","Epoch 90: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 5.0938 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 91/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9972\n","Epoch 91: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 4.7750 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 92/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n","Epoch 92: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 4.8440 - val_accuracy: 0.6397 - lr: 0.0010\n","Epoch 93/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9948\n","Epoch 93: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 101s 1s/step - loss: 0.0251 - accuracy: 0.9948 - val_loss: 4.4820 - val_accuracy: 0.6342 - lr: 0.0010\n","Epoch 94/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9984\n","Epoch 94: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0123 - accuracy: 0.9984 - val_loss: 4.9675 - val_accuracy: 0.6416 - lr: 0.0010\n","Epoch 95/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9964\n","Epoch 95: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 4.1178 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 96/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9972\n","Epoch 96: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 0.0202 - accuracy: 0.9972 - val_loss: 3.7915 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 97/100\n","79/79 [==============================] - ETA: 0s - loss: 7.3048e-04 - accuracy: 1.0000\n","Epoch 97: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 7.3048e-04 - accuracy: 1.0000 - val_loss: 3.8044 - val_accuracy: 0.6713 - lr: 0.0010\n","Epoch 98/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n","Epoch 98: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 103s 1s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 4.0120 - val_accuracy: 0.6713 - lr: 0.0010\n","Epoch 99/100\n","79/79 [==============================] - ETA: 0s - loss: 5.3659e-04 - accuracy: 1.0000\n","Epoch 99: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 101s 1s/step - loss: 5.3659e-04 - accuracy: 1.0000 - val_loss: 3.8996 - val_accuracy: 0.6695 - lr: 0.0010\n","Epoch 100/100\n","79/79 [==============================] - ETA: 0s - loss: 1.4734e-04 - accuracy: 1.0000\n","Epoch 100: val_accuracy did not improve from 0.67967\n","79/79 [==============================] - 102s 1s/step - loss: 1.4734e-04 - accuracy: 1.0000 - val_loss: 3.9972 - val_accuracy: 0.6741 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa50c50e390>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model2.load_weights(resultPath + \"/checkpoint-0015.hdf5\")"],"metadata":{"id":"3axDauUb8-MX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction_prob1 = model2.predict(x_test,verbose=1)\n","y_pred=np.round(prediction_prob1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujafe8lgnGNg","executionInfo":{"status":"ok","timestamp":1657901511361,"user_tz":-330,"elapsed":21846,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"59aa7eba-dd8b-4e65-836c-aaf6dbf33b22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 12s 327ms/step\n"]}]},{"cell_type":"code","source":["m1model = Model(inputs=model2.input,outputs=model2.get_layer('dense_1').output)"],"metadata":{"id":"oXW0pdf6oRnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m1_x_train = m1model.predict(x_train,verbose=1)\n","m1_x_test = m1model.predict(x_test,verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67qafxvCoZmK","executionInfo":{"status":"ok","timestamp":1657901573855,"user_tz":-330,"elapsed":36496,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"901995a4-dede-46f0-8b2e-1bd1ab1864e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 25s 314ms/step\n","34/34 [==============================] - 10s 304ms/step\n"]}]},{"cell_type":"code","source":["print(\"Shape of model1 Train and Test DF : \",m1_x_train.shape,\" : \",m1_x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmYzO1adodUT","executionInfo":{"status":"ok","timestamp":1657901583342,"user_tz":-330,"elapsed":539,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"cf9b1ee7-95a1-4997-fa03-2ed78e56dca2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of model1 Train and Test DF :  (2511, 1)  :  (1077, 1)\n"]}]},{"cell_type":"code","source":["def printMetrics(true,pred):\n","    print(\"Accuracy : \",accuracy_score(true, pred))\n","    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n","    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n","    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n","    print(\"Confusion Matrix : \")\n","    print(confusion_matrix(true, pred))\n","    print(classification_report(true,pred))"],"metadata":{"id":"EdMMF48yooa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RSVM = svm.SVC(kernel='rbf',probability=True)\n","RSVM.fit(m1_x_train, y_train)\n","RSVMprob = RSVM.predict_proba(m1_x_test)\n","y_pred = RSVM.predict(m1_x_test)\n","print(\"cost-insensitive\")\n","printMetrics(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOni1uYLotAN","executionInfo":{"status":"ok","timestamp":1657901637312,"user_tz":-330,"elapsed":1484,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"97092c02-09fe-4db7-aff3-d1a799600989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cost-insensitive\n","Accuracy :  0.6833797585886723\n","Precision 0.6831189081190299\n","Recall :  0.6833797585886723\n","F1-score :  0.6830361699251003\n","Confusion Matrix : \n","[[335 180]\n"," [161 401]]\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.65      0.66       515\n","           1       0.69      0.71      0.70       562\n","\n","    accuracy                           0.68      1077\n","   macro avg       0.68      0.68      0.68      1077\n","weighted avg       0.68      0.68      0.68      1077\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wTaeh7ypo05b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gender Classification"],"metadata":{"id":"Hp9c8WGsFxSQ"}},{"cell_type":"code","source":["DATA_PATH = '/content/drive/MyDrive/MlProject1/ML_project1/Gender/'\n","genderData=[]\n","glabel=[]\n","ghashList=[]\n","count=2\n","for folder in os.listdir(DATA_PATH):\n","    print(\">>>Reading \",folder)\n","    count-=1\n","    print(count)\n","    \n","    for file in os.listdir(DATA_PATH+folder):\n","         if(str(file).endswith('.jpg') or str(file).endswith('.JPG') or str(file).endswith('.jpeg') or str(file).endswith('.JPEG')):\n","            img = image.imread(DATA_PATH+folder+'/'+file)\n","            hsh = hash(tuple(np.array(img).flatten()))\n","            if(hsh not in ghashList):\n","              genderData.append(resize(img, (156, 156, 3)))\n","              ghashList.append(hsh)\n","              glabel.append(count)\n","genderData=np.array(genderData)\n","glabel=np.array(glabel)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0JoCdXbFzto","executionInfo":{"status":"ok","timestamp":1657977718465,"user_tz":-330,"elapsed":341793,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"5712eca1-3790-4519-cd8f-c567c1498aa7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[">>>Reading  male\n","1\n",">>>Reading  female\n","0\n"]}]},{"cell_type":"code","source":["resultPath = '/content/drive/MyDrive/MlProject1/gResult'\n","train_folder = os.listdir(DATA_PATH)"],"metadata":{"id":"nj2O8Q8sF_Un","executionInfo":{"status":"ok","timestamp":1657977983349,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"Number of maleGarments\",len(glabel[glabel==0]))\n","print(\"Number of femaleGarments\",len(glabel[glabel==1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCJ4la-ULVr1","executionInfo":{"status":"ok","timestamp":1657977999845,"user_tz":-330,"elapsed":532,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"cce9d5b4-9a96-412a-f25b-b5f43443ccb8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of maleGarments 1825\n","Number of femaleGarments 1797\n"]}]},{"cell_type":"code","source":["print(\"Gender data shape : \",genderData.shape,\" Label shape : \",glabel.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lZpkvQEMIpQ","executionInfo":{"status":"ok","timestamp":1657978016791,"user_tz":-330,"elapsed":432,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"3dc823a0-7f84-4826-a5e9-5b21827f5beb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Gender data shape :  (3622, 156, 156, 3)  Label shape :  (3622,)\n"]}]},{"cell_type":"code","source":["testPercentage=0.3\n","x_train,x_test,y_train,y_test = train_test_split(genderData,glabel,test_size = testPercentage,random_state=50, stratify=glabel,shuffle=True)"],"metadata":{"id":"Wqk-i6QmMMyn","executionInfo":{"status":"ok","timestamp":1657978048067,"user_tz":-330,"elapsed":6658,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(\"x_train shape : \",x_train.shape,\" y_train shape : \",y_train.shape)\n","print(\"x_test shape : \",x_test.shape,\" y_test shape : \",y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txfq0S3LMS5U","executionInfo":{"status":"ok","timestamp":1657978058045,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"4fcf25d5-2489-4384-9f87-7cc0d170b937"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape :  (2535, 156, 156, 3)  y_train shape :  (2535,)\n","x_test shape :  (1087, 156, 156, 3)  y_test shape :  (1087,)\n"]}]},{"cell_type":"code","source":["print(\"Number of train male male\",len(y_train[y_train==0]))\n","print(\"Number of train female garments\",len(y_train[y_train==1]))\n","\n","print(\"Number of test male garments \",len(y_test[y_test==0]))\n","print(\"Number of test female garments\",len(y_test[y_test==1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHJLE5hOMW7-","executionInfo":{"status":"ok","timestamp":1657978071212,"user_tz":-330,"elapsed":542,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"81e39e49-a5e5-4c18-9044-1d6e7083683a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train male male 1277\n","Number of train female garments 1258\n","Number of test male garments  548\n","Number of test female garments 539\n"]}]},{"cell_type":"code","source":["checkpointer = callbacks.ModelCheckpoint(filepath=resultPath+\"/checkpoint-{epoch:04d}.hdf5\", verbose=1, save_best_only=True, monitor='val_accuracy',mode='max')\n","csv_logger = CSVLogger(resultPath+'/result_logger.csv',separator=',', append=False)\n","reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.2, patience=2, min_lr=0.001)\n","model2.fit(x_train,y_train,epochs=NO_OF_EPOCHS,verbose=1,batch_size=BATCH_SIZE,validation_data=(x_test,y_test),callbacks=[checkpointer,csv_logger,reduce_lr])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktxqcpkyMaCy","executionInfo":{"status":"ok","timestamp":1657992836659,"user_tz":-330,"elapsed":3252575,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"54791be1-e9f4-4123-8d91-f3e693da3852"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","79/79 [==============================] - ETA: 0s - loss: 0.9594 - accuracy: 0.5424\n","Epoch 1: val_accuracy improved from -inf to 0.55246, saving model to /content/drive/MyDrive/Results1/checkpoint-0001.hdf5\n","79/79 [==============================] - 150s 2s/step - loss: 0.9594 - accuracy: 0.5424 - val_loss: 0.6755 - val_accuracy: 0.5525 - lr: 0.0010\n","Epoch 2/100\n","79/79 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.6181\n","Epoch 2: val_accuracy improved from 0.55246 to 0.59796, saving model to /content/drive/MyDrive/Results1/checkpoint-0002.hdf5\n","79/79 [==============================] - 150s 2s/step - loss: 0.6586 - accuracy: 0.6181 - val_loss: 0.6676 - val_accuracy: 0.5980 - lr: 0.0010\n","Epoch 3/100\n","79/79 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.6802\n","Epoch 3: val_accuracy improved from 0.59796 to 0.64253, saving model to /content/drive/MyDrive/Results1/checkpoint-0003.hdf5\n","79/79 [==============================] - 152s 2s/step - loss: 0.5976 - accuracy: 0.6802 - val_loss: 0.6575 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 4/100\n","79/79 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.7113\n","Epoch 4: val_accuracy improved from 0.64253 to 0.66017, saving model to /content/drive/MyDrive/Results1/checkpoint-0004.hdf5\n","79/79 [==============================] - 151s 2s/step - loss: 0.5431 - accuracy: 0.7113 - val_loss: 0.7113 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 5/100\n","79/79 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8041\n","Epoch 5: val_accuracy did not improve from 0.66017\n","79/79 [==============================] - 147s 2s/step - loss: 0.4115 - accuracy: 0.8041 - val_loss: 0.8976 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 6/100\n","79/79 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8483\n","Epoch 6: val_accuracy did not improve from 0.66017\n","79/79 [==============================] - 148s 2s/step - loss: 0.3240 - accuracy: 0.8483 - val_loss: 0.9812 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 7/100\n","79/79 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9136\n","Epoch 7: val_accuracy improved from 0.66017 to 0.67038, saving model to /content/drive/MyDrive/Results1/checkpoint-0007.hdf5\n","79/79 [==============================] - 152s 2s/step - loss: 0.2161 - accuracy: 0.9136 - val_loss: 1.3089 - val_accuracy: 0.6704 - lr: 0.0010\n","Epoch 8/100\n","79/79 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9474\n","Epoch 8: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.1263 - accuracy: 0.9474 - val_loss: 1.6558 - val_accuracy: 0.6453 - lr: 0.0010\n","Epoch 9/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9713\n","Epoch 9: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0976 - accuracy: 0.9713 - val_loss: 1.8980 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 10/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9749\n","Epoch 10: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0649 - accuracy: 0.9749 - val_loss: 2.1667 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 11/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9805\n","Epoch 11: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0580 - accuracy: 0.9805 - val_loss: 2.1583 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 12/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9885\n","Epoch 12: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 2.5570 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 13/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9944\n","Epoch 13: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 150s 2s/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 2.6919 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 14/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9952\n","Epoch 14: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 2.7473 - val_accuracy: 0.6676 - lr: 0.0010\n","Epoch 15/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9924\n","Epoch 15: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 3.2099 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 16/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9960\n","Epoch 16: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 3.1037 - val_accuracy: 0.6555 - lr: 0.0010\n","Epoch 17/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n","Epoch 17: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 3.0681 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 18/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980\n","Epoch 18: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 3.5044 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 19/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9924\n","Epoch 19: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 2.9388 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 20/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9781\n","Epoch 20: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 2.4447 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 21/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9904\n","Epoch 21: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 2.6360 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 22/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9781\n","Epoch 22: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0826 - accuracy: 0.9781 - val_loss: 2.4489 - val_accuracy: 0.6212 - lr: 0.0010\n","Epoch 23/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9920\n","Epoch 23: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 2.8912 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 24/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9976\n","Epoch 24: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 2.8541 - val_accuracy: 0.6574 - lr: 0.0010\n","Epoch 25/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9976\n","Epoch 25: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 151s 2s/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 2.8440 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 26/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9976\n","Epoch 26: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 2.9638 - val_accuracy: 0.6518 - lr: 0.0010\n","Epoch 27/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n","Epoch 27: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 2.8807 - val_accuracy: 0.6537 - lr: 0.0010\n","Epoch 28/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9964\n","Epoch 28: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 2.9301 - val_accuracy: 0.6685 - lr: 0.0010\n","Epoch 29/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964\n","Epoch 29: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 3.4896 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 30/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n","Epoch 30: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 3.1814 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 31/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984\n","Epoch 31: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 3.4785 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 32/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9968\n","Epoch 32: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0080 - accuracy: 0.9968 - val_loss: 4.1463 - val_accuracy: 0.6555 - lr: 0.0010\n","Epoch 33/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9956\n","Epoch 33: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 3.3252 - val_accuracy: 0.6407 - lr: 0.0010\n","Epoch 34/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9980\n","Epoch 34: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 148s 2s/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 3.5533 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 35/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9968\n","Epoch 35: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 3.6656 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 36/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9976\n","Epoch 36: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 3.5520 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 37/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9952\n","Epoch 37: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 3.1327 - val_accuracy: 0.6685 - lr: 0.0010\n","Epoch 38/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9976\n","Epoch 38: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 141s 2s/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 3.3476 - val_accuracy: 0.6407 - lr: 0.0010\n","Epoch 39/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9980\n","Epoch 39: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 140s 2s/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 3.6772 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 40/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9976\n","Epoch 40: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 143s 2s/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 3.2475 - val_accuracy: 0.6444 - lr: 0.0010\n","Epoch 41/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9996\n","Epoch 41: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 142s 2s/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 3.2692 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 42/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9988\n","Epoch 42: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 3.3083 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 43/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 43: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3667 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 44/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n","Epoch 44: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 3.4646 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 45/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9992\n","Epoch 45: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 143s 2s/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 3.3843 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 46/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9976\n","Epoch 46: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 3.5168 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 47/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n","Epoch 47: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 143s 2s/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 3.7265 - val_accuracy: 0.6305 - lr: 0.0010\n","Epoch 48/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9940\n","Epoch 48: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0263 - accuracy: 0.9940 - val_loss: 3.7713 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 49/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9952\n","Epoch 49: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 3.0247 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 50/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9956\n","Epoch 50: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 150s 2s/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 3.1272 - val_accuracy: 0.6565 - lr: 0.0010\n","Epoch 51/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n","Epoch 51: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 3.4241 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 52/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9988\n","Epoch 52: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 149s 2s/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 3.7382 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 53/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9992\n","Epoch 53: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 3.5389 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 54/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 54: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 3.8680 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 55/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 55: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 3.9134 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 56/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 56: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 3.7248 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 57/100\n","79/79 [==============================] - ETA: 0s - loss: 7.7052e-04 - accuracy: 1.0000\n","Epoch 57: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 7.7052e-04 - accuracy: 1.0000 - val_loss: 3.8676 - val_accuracy: 0.6657 - lr: 0.0010\n","Epoch 58/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 58: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 3.8030 - val_accuracy: 0.6648 - lr: 0.0010\n","Epoch 59/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n","Epoch 59: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 144s 2s/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 3.6992 - val_accuracy: 0.6592 - lr: 0.0010\n","Epoch 60/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 60: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.7205 - val_accuracy: 0.6583 - lr: 0.0010\n","Epoch 61/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 61: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.8165 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 62/100\n","79/79 [==============================] - ETA: 0s - loss: 9.9888e-04 - accuracy: 0.9996\n","Epoch 62: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 146s 2s/step - loss: 9.9888e-04 - accuracy: 0.9996 - val_loss: 3.9176 - val_accuracy: 0.6676 - lr: 0.0010\n","Epoch 63/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 63: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.9237 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 64/100\n","79/79 [==============================] - ETA: 0s - loss: 9.9723e-04 - accuracy: 0.9996\n","Epoch 64: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 147s 2s/step - loss: 9.9723e-04 - accuracy: 0.9996 - val_loss: 3.9412 - val_accuracy: 0.6676 - lr: 0.0010\n","Epoch 65/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 65: val_accuracy did not improve from 0.67038\n","79/79 [==============================] - 145s 2s/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.9751 - val_accuracy: 0.6676 - lr: 0.0010\n","Epoch 66/100\n","79/79 [==============================] - ETA: 0s - loss: 7.4993e-04 - accuracy: 0.9996\n","Epoch 66: val_accuracy improved from 0.67038 to 0.67224, saving model to /content/drive/MyDrive/Results1/checkpoint-0066.hdf5\n","79/79 [==============================] - 148s 2s/step - loss: 7.4993e-04 - accuracy: 0.9996 - val_loss: 3.8950 - val_accuracy: 0.6722 - lr: 0.0010\n","Epoch 67/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 67: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 146s 2s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 3.9299 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 68/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n","Epoch 68: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 146s 2s/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 4.5592 - val_accuracy: 0.6453 - lr: 0.0010\n","Epoch 69/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9972\n","Epoch 69: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 4.2140 - val_accuracy: 0.6416 - lr: 0.0010\n","Epoch 70/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n","Epoch 70: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 143s 2s/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 4.3601 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 71/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9988\n","Epoch 71: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 142s 2s/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 3.9328 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 72/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9960\n","Epoch 72: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0101 - accuracy: 0.9960 - val_loss: 5.2457 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 73/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9932\n","Epoch 73: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 145s 2s/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 4.3902 - val_accuracy: 0.6527 - lr: 0.0010\n","Epoch 74/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9960\n","Epoch 74: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 4.6619 - val_accuracy: 0.6574 - lr: 0.0010\n","Epoch 75/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9976\n","Epoch 75: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 4.2676 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 76/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9964\n","Epoch 76: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 3.7006 - val_accuracy: 0.6490 - lr: 0.0010\n","Epoch 77/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984\n","Epoch 77: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 140s 2s/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 3.9768 - val_accuracy: 0.6444 - lr: 0.0010\n","Epoch 78/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9968\n","Epoch 78: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0057 - accuracy: 0.9968 - val_loss: 4.7321 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 79/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n","Epoch 79: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 142s 2s/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 4.3746 - val_accuracy: 0.6602 - lr: 0.0010\n","Epoch 80/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 80: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 146s 2s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 4.4569 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 81/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9988\n","Epoch 81: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 4.4821 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 82/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9992\n","Epoch 82: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 146s 2s/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 4.5818 - val_accuracy: 0.6472 - lr: 0.0010\n","Epoch 83/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 83: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 144s 2s/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 4.5830 - val_accuracy: 0.6481 - lr: 0.0010\n","Epoch 84/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9956\n","Epoch 84: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 146s 2s/step - loss: 0.0204 - accuracy: 0.9956 - val_loss: 4.7825 - val_accuracy: 0.6657 - lr: 0.0010\n","Epoch 85/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9960\n","Epoch 85: val_accuracy did not improve from 0.67224\n","79/79 [==============================] - 145s 2s/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 5.2799 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 86/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n","Epoch 86: val_accuracy improved from 0.67224 to 0.67317, saving model to /content/drive/MyDrive/Results1/checkpoint-0086.hdf5\n","79/79 [==============================] - 148s 2s/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 5.1444 - val_accuracy: 0.6732 - lr: 0.0010\n","Epoch 87/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n","Epoch 87: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 149s 2s/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 4.9412 - val_accuracy: 0.6500 - lr: 0.0010\n","Epoch 88/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9964\n","Epoch 88: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 4.7044 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 89/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9984\n","Epoch 89: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 144s 2s/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 5.1130 - val_accuracy: 0.6546 - lr: 0.0010\n","Epoch 90/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9976\n","Epoch 90: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 5.6760 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 91/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9896\n","Epoch 91: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 144s 2s/step - loss: 0.0432 - accuracy: 0.9896 - val_loss: 4.7019 - val_accuracy: 0.6685 - lr: 0.0010\n","Epoch 92/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9956\n","Epoch 92: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 145s 2s/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 4.2790 - val_accuracy: 0.6630 - lr: 0.0010\n","Epoch 93/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n","Epoch 93: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 142s 2s/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 4.5137 - val_accuracy: 0.6639 - lr: 0.0010\n","Epoch 94/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 94: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 4.6407 - val_accuracy: 0.6648 - lr: 0.0010\n","Epoch 95/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 95: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 144s 2s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.5784 - val_accuracy: 0.6620 - lr: 0.0010\n","Epoch 96/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 96: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.5157 - val_accuracy: 0.6611 - lr: 0.0010\n","Epoch 97/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 97: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 4.9093 - val_accuracy: 0.6648 - lr: 0.0010\n","Epoch 98/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9956\n","Epoch 98: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 146s 2s/step - loss: 0.0311 - accuracy: 0.9956 - val_loss: 4.3273 - val_accuracy: 0.6425 - lr: 0.0010\n","Epoch 99/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9968\n","Epoch 99: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 144s 2s/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 4.1784 - val_accuracy: 0.6462 - lr: 0.0010\n","Epoch 100/100\n","79/79 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n","Epoch 100: val_accuracy did not improve from 0.67317\n","79/79 [==============================] - 145s 2s/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 4.6034 - val_accuracy: 0.6518 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff83c377a50>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["model2.load_weights(resultPath + \"/checkpoint-0086.hdf5\")"],"metadata":{"id":"UtNcRWIQMfDz","executionInfo":{"status":"ok","timestamp":1657992855588,"user_tz":-330,"elapsed":1158,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["prediction_prob1 = model2.predict(x_test,verbose=1)\n","y_pred=np.round(prediction_prob1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ3u1IxEEzeY","executionInfo":{"status":"ok","timestamp":1657992926336,"user_tz":-330,"elapsed":45707,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"87dc0ee7-11bc-499c-dd9e-dacd4d079638"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 26s 711ms/step\n"]}]},{"cell_type":"code","source":["m1model = Model(inputs=model2.input,outputs=model2.get_layer('dense_1').output)"],"metadata":{"id":"JBvfPW2wE58n","executionInfo":{"status":"ok","timestamp":1657992929721,"user_tz":-330,"elapsed":639,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["m1_x_train = m1model.predict(x_train,verbose=1)\n","m1_x_test = m1model.predict(x_test,verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"an2qj8JQFFrf","executionInfo":{"status":"ok","timestamp":1657993003663,"user_tz":-330,"elapsed":64614,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"6d8d1877-0d65-4238-d643-8a0dfad19d63"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 32s 403ms/step\n","34/34 [==============================] - 13s 389ms/step\n"]}]},{"cell_type":"code","source":["print(\"Shape of model1 Train and Test DF : \",m1_x_train.shape,\" : \",m1_x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylxo0Ag4FINp","executionInfo":{"status":"ok","timestamp":1657993028001,"user_tz":-330,"elapsed":515,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"68cf5ab8-9ac7-494f-f09c-5ded812e87c5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of model1 Train and Test DF :  (2511, 1)  :  (1077, 1)\n"]}]},{"cell_type":"code","source":["def printMetrics(true,pred):\n","    print(\"Accuracy : \",accuracy_score(true, pred))\n","    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n","    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n","    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n","    print(\"Confusion Matrix : \")\n","    print(confusion_matrix(true, pred))\n","    print(classification_report(true,pred))"],"metadata":{"id":"lmaD_kRKFdyZ","executionInfo":{"status":"ok","timestamp":1657993053637,"user_tz":-330,"elapsed":464,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["RSVM = svm.SVC(kernel='rbf',probability=True)\n","RSVM.fit(m1_x_train, y_train)\n","RSVMprob = RSVM.predict_proba(m1_x_test)\n","y_pred = RSVM.predict(m1_x_test)\n","print(\"cost-insensitive\")\n","printMetrics(y_test,y_pred)"],"metadata":{"id":"fTLX9R5dFkEu","executionInfo":{"status":"ok","timestamp":1657993063722,"user_tz":-330,"elapsed":498,"user":{"displayName":"Ritika Sinha","userId":"15779898979330952076"}},"outputId":"772b5a14-0b93-4da6-c57c-6c807636b474","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["cost-insensitive\n","Accuracy :  0.6731662024141133\n","Precision 0.6729064913346853\n","Recall :  0.6731662024141133\n","F1-score :  0.6725119683825506\n","Confusion Matrix : \n","[[324 191]\n"," [161 401]]\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.63      0.65       515\n","           1       0.68      0.71      0.69       562\n","\n","    accuracy                           0.67      1077\n","   macro avg       0.67      0.67      0.67      1077\n","weighted avg       0.67      0.67      0.67      1077\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"3_zoOHEIFmhN"},"execution_count":null,"outputs":[]}]}